# (Proyecto IA) Predicci√≥n de Parkinson mediante An√°lisis de Voz

<img src="https://tse1.mm.bing.net/th/id/OIP.djjJfRjmIgCcUG2jmMhsQAHaHa?rs=1&pid=ImgDetMain&o=7&rm=3" width="100" height="100" alt="Logo de la Unimag">

Este repositorio contiene el proyecto final para la asignatura de Inteligencia Artificial de la Universidad del Magdalena. El objetivo es desarrollar y evaluar un modelo de Machine Learning capaz de predecir la presencia de la enfermedad de Parkinson bas√°ndose en grabaciones de se√±ales de voz.

**Autores:**
* Jose Torreglosa cod. 2019219044
* Jennifer Roa
* Lauren Gonzales

---

### üí° Sobre el Proyecto

Este proyecto utiliza el conjunto de datos "Parkinson's Disease Data Set" de la Universidad de Oxford. El dataset consiste en 195 grabaciones de voz de 31 individuos (23 con Parkinson y 8 sanos). Se extrajeron 22 caracter√≠sticas biom√©dicas de cada grabaci√≥n (como *jitter*, *shimmer*, y frecuencias fundamentales).

El objetivo principal es clasificar correctamente a un paciente como "Sano" (0) o "Parkinson" (1) usando estas caracter√≠sticas.

### Ï±å Desaf√≠o Principal: Desbalanceo de Clases

El desaf√≠o m√°s significativo de este dataset es el **desbalanceo de clases**. De las 195 muestras:
* **147 (75%)** pertenecen a pacientes con Parkinson (Clase 1).
* **48 (25%)** pertenecen a pacientes sanos (Clase 0).

Un modelo simple entrenado con estos datos tender√° a predecir siempre "Parkinson", logrando un accuracy artificialmente alto pero siendo in√∫til para detectar pacientes sanos. Este notebook explora activamente soluciones a este problema.

---

### üî¨ Flujo de Trabajo (Workflow)

El notebook `PARKINSONll.ipynb` est√° estructurado de la siguiente manera:

1.  **Carga e Inspecci√≥n:** Se cargan los datos y se verifica su integridad (sin valores nulos o duplicados).
2.  **An√°lisis Exploratorio (EDA):**
    * Visualizaci√≥n de las distribuciones de las caracter√≠sticas.
    * An√°lisis de la variable objetivo (`status`) para confirmar el desbalanceo.
    * Estudio de **multicolinealidad** mediante un *heatmap*, revelando alta correlaci√≥n entre muchas caracter√≠sticas.
3.  **Preprocesamiento y Selecci√≥n de Caracter√≠sticas:**
    * Debido a la alta multicolinealidad, se aplic√≥ **Regresi√≥n Log√≠stica con regularizaci√≥n L1 (Lasso)**.
    * Esta t√©cnica seleccion√≥ las **13 caracter√≠sticas m√°s relevantes** de las 22 originales, eliminando la redundancia.
    * Los datos fueron estandarizados usando `StandardScaler`.
4.  **Modelado y Experimentaci√≥n:**
    * Se compararon m√∫ltiples estrategias para manejar el desbalanceo y maximizar el rendimiento.
    * **M√©todo 1:** Regresi√≥n Log√≠stica + **SMOTE** (Accuracy: 76%).
    * **M√©todo 2:** Random Forest + **Ponderaci√≥n de Clases** (Accuracy: 93%).
    * **M√©todo 3:** Optimizaci√≥n del M√©todo 2 usando **GridSearchCV** (Accuracy: 93%).
    * **M√©todo 4:** Random Forest (Baseline, *sin* balanceo) (Accuracy: 95%).
    * **M√©todo 5 (CAMPE√ìN):** Random Forest + **SMOTE** (Accuracy: 97%).

---

### üèÜ Resultados y Modelo Final

El modelo final, un **`RandomForestClassifier`** entrenado sobre datos aumentados con **SMOTE** (Synthetic Minority Over-sampling Technique), demostr√≥ ser el m√°s robusto, alcanzando un **accuracy del 97%** en el conjunto de prueba (Celda 51).

Este modelo fue capaz de manejar exitosamente el desbalanceo, produciendo una matriz de confusi√≥n casi perfecta en el set de prueba, con solo 1 Falso Positivo y 1 Falso Negativo.

#### Comparativa de Modelos Finales

| Estrategia de Modelo (Random Forest) | Accuracy | Falsos Positivos | Falsos Negativos |
| :--- | :---: | :---: | :---: |
| **RF + SMOTE (Modelo Ganador)** | **97%** | **1** | **1** |
| RF (Sin t√©cnica de balanceo) | 95% | 1 | 2 |
| RF + Ponderaci√≥n de Clases | 93% | 3 | 1 |
| Regresi√≥n Log√≠stica + SMOTE | 76% | 12 | 2 |

---

### üõ†Ô∏è C√≥mo ejecutar este proyecto

1.  Clona el repositorio:
    ```sh
    git clone [https://github.com/TU_USUARIO/TU_REPOSITORIO.git](https://github.com/TU_USUARIO/TU_REPOSITORIO.git)
    ```
2.  Crea un entorno virtual e instala las dependencias (puedes crear un `requirements.txt`):
    ```
    pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn jupyter
    ```
3.  Abre el notebook `PARKINSONll.ipynb` usando Jupyter Lab o Jupyter Notebook.
4.  Aseg√∫rate de que el archivo `parkinsons.data` est√© en una carpeta `/data/` al mismo nivel que el notebook.

---

### üì© 

AtromicLink(LinkedGTF)
Jose Torreglosa.

<img src="https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExOHlvMmg5ajAwMnZxdGVtZGIzNGltbDIwb2xudnU0aDNoN3BxeTI5eSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/JGMaGy5beukJ96I5Xw/giphy.gif" alt="Descripci√≥n del GIF" width="640">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/jtorreglosam/)
[![Gmail](https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:josddaniel1@gmail.com)

---
